#! /usr/bin/bash
##### use this for training
python ./dagger_train_perception_aware.py \
    --n_rollout_threads 1 \
    --n_training_threads 1 \
    --num_mini_batch 1 \
    --algorithm_name mappo \
    --episode_length 170 \
    --stage_two_episode_length 170 \
    --env_name LearningPA \
    --experiment_name maze-mid \
    --use_recurrent_policy \
    --mlp_hidden_size 256 \
    --layer_N 1 \
    --log_interval 2 \
    --save_interval 20 \
    --num_env_steps 500000 \
    --ppo_epoch 6 \
    --max_grad_norm 8.0 \
    --seed 1 \
    --device cuda:0 \
    --scene_path scene/maze-mid \
    --vec_env_config flightlib/configs/vec_env.yaml \
    --env_config flightlib/configs/quadrotor_env.yaml \
    --dyn_config flightlib/configs/dyn_param.yaml \
    --gate_radius 0.7 \
    --user_name <user_name> \
    --wandb_name <wandb_name> \
    --gate_num 1 \
    --gate0_x 7.0 \
    --gate0_y -12.0 \
    --gate0_z 2.5 \
    --gate0_angle -60 \
    --model_dir /home/<user_name>/workspace/flightmare_ws/src/flightmare/flightbench/lpa_policy/maze-mid-teacher/run-20240419_220908-qasm3maa/files \
    --pretrain_dir /home/<user_name>/workspace/flightmare_ws/src/flightmare/flightrl/onpolicy/runner/PAnet.pt \
    --data_dir /home/<user_name>/workspace/flightmare_ws/src/flightmare/flightrl/onpolicy/data \
    --eval_dir /home/<user_name>/workspace/flightmare_ws/src/flightmare/flightrl/onpolicy/eval \
    --use_unity \
    --scene_id 3